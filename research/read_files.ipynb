{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "import os\n",
    "\n",
    "from src.entity.artifact_entity import FileHandlerArtifact\n",
    "from src.logger import get_logger\n",
    "\n",
    "\n",
    "class ReadFiles:\n",
    "    def __init__(self, file_handler_artifact: FileHandlerArtifact):\n",
    "        self.file_handler_artifact = file_handler_artifact\n",
    "        self.logger = get_logger(__name__)\n",
    "        \n",
    "        \n",
    "    def check_file_type(self,file_path):\n",
    "        # Define the allowed file types\n",
    "        allowed_file_types = {\n",
    "            'application/pdf': 'PDF',\n",
    "            'application/vnd.ms-powerpoint': 'PPT',\n",
    "            'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'PPTX',\n",
    "            'application/msword': 'DOC',\n",
    "            'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'DOCX',\n",
    "            'image/png': 'PNG',\n",
    "            'image/jpeg': 'JPG',\n",
    "            'application/vnd.ms-excel': 'XLS',\n",
    "            'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': 'XLSX',\n",
    "            'text/csv': 'CSV',\n",
    "            'text/markdown': 'MD',\n",
    "            'text/html': 'HTML'\n",
    "        }\n",
    "\n",
    "        # Get the MIME type of the file\n",
    "        mime_type, _ = mimetypes.guess_type(file_path)\n",
    "\n",
    "        # Check if the MIME type is in the allowed file types\n",
    "        if mime_type in allowed_file_types:\n",
    "            return allowed_file_types[mime_type]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def get_file_names_and_types(self) -> list[dict]:\n",
    "        file_details = []\n",
    "        for file in os.listdir(self.file_handler_artifact.file_storage_dir):\n",
    "            file_full_path = os.path.join(self.file_handler_artifact.file_storage_dir,\n",
    "                                          file)\n",
    "            if os.path.isfile(file_full_path):\n",
    "                file_details.append({\n",
    "                    'filename': file,\n",
    "                    \"full_path\":file_full_path,\n",
    "                    'file_type': self.check_file_type(file_full_path)\n",
    "                })\n",
    "        return file_details\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artifact = FileHandlerArtifact(\n",
    "    file_storage_dir=\"artifacts/06_26_2024_12_48_34/file_storage/testmyne45\"\n",
    ")\n",
    "rf = ReadFiles(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.get_file_names_and_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "pdf_path = 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf'\n",
    "\n",
    "loader = PyPDFLoader(pdf_path, extract_images=True)\n",
    "pages1 = loader.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[43mRecursiveCharacterTextSplitter\u001b[49m(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      2\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, \n\u001b[1;32m      3\u001b[0m     separators\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m splits \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit_documents(pages1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "    chunk_overlap=200, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "splits = splitter.split_documents(pages1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
    "\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"artifacts/06_26_2024_12_48_34/file_storage/testmyne45/screenshot-(3).png\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from docx2pdf import convert\n",
    "\n",
    "from src.exception import CustomException\n",
    "from langchain_text_splitters.base import TextSplitter\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredExcelLoader,\n",
    "    UnstructuredCSVLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    UnstructuredHTMLLoader,\n",
    "    UnstructuredImageLoader,\n",
    "    ImageCaptionLoader,\n",
    "    Docx2txtLoader,\n",
    "    AmazonTextractPDFLoader)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def load_and_split_document(loader_class, file_path, splitter: TextSplitter, **loader_kwargs):\n",
    "    \"\"\"\n",
    "    Generic function to load and split documents using a specified loader class and text splitter.\n",
    "\n",
    "\n",
    "    :param loader_class: The document loader class to use.\n",
    "    :param file_path: The path to the document file.\n",
    "    :param splitter: The text splitter to use for splitting the document.\n",
    "    :param loader_kwargs: Additional keyword arguments to pass to the loader.\n",
    "    :return: Chunks of documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loader = loader_class(file_path, **loader_kwargs)\n",
    "        docs = loader.load()\n",
    "        doc_splits = splitter.split_documents(docs)\n",
    "        return doc_splits\n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "def read_pdf_pypdf(pdf_path, splitter: TextSplitter):\n",
    "    \"\"\"Read PDFs, implement OCR for images within PDF, and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(PyPDFLoader, pdf_path, splitter, extract_images=True)\n",
    "\n",
    "def read_with_aws(file_path, splitter: TextSplitter, **kwargs):\n",
    "    \"\"\"Read PDFs,images using amazon texract, and return a list of chunks of documents.\n",
    "    This can read texts from images, \n",
    "    images within pdfs,\n",
    "    text in pdfs,\"\"\"\n",
    "    return load_and_split_document(AmazonTextractPDFLoader, file_path, splitter, **kwargs)\n",
    "\n",
    "\n",
    "def read_txt(txt_path, splitter: TextSplitter):\n",
    "    \"\"\"Read text files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(TextLoader, txt_path, splitter)\n",
    "\n",
    "# Additional functions for other document types can be implemented similarly.\n",
    "def read_excel(excel_path, splitter: TextSplitter):\n",
    "    \"\"\"Read Excel files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(UnstructuredExcelLoader, excel_path, splitter)\n",
    "\n",
    "def read_csv(csv_path, splitter: TextSplitter):\n",
    "    \"\"\"Read CSV files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(UnstructuredCSVLoader, csv_path, splitter)\n",
    "\n",
    "def read_markdown(md_path, splitter: TextSplitter):\n",
    "    \"\"\"Read Markdown files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(UnstructuredMarkdownLoader, md_path, splitter)\n",
    "\n",
    "def read_ppt(ppt_path, splitter: TextSplitter):\n",
    "    \"\"\"Read PowerPoint files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(UnstructuredPowerPointLoader, ppt_path, splitter)\n",
    "\n",
    "# def read_docx(docx_path, splitter: TextSplitter):\n",
    "#     \"\"\"Read PowerPoint files and return a list of chunks of documents.\"\"\"\n",
    "#     #convert docx to pdf to extract texts from images within the doc effectively\n",
    "#     file_dir = os.path.dirname(docx_path)\n",
    "#     file_name = os.path.basename(docx_path).split('.')[0]\n",
    "#     file_ext = \".pdf\"\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # return load_and_split_document(Docx2txtLoader, docx_path, splitter)\n",
    "\n",
    "def read_html(html_path, splitter: TextSplitter):\n",
    "    \"\"\"Read HTML files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(UnstructuredHTMLLoader, html_path, splitter)\n",
    "\n",
    "def read_image(image_path, splitter: TextSplitter):\n",
    "    \"\"\"Read image files and return a list of chunks of documents.\"\"\"\n",
    "    return load_and_split_document(UnstructuredImageLoader, image_path, splitter)\n",
    "\n",
    "def read_image_caption(image_path, splitter: TextSplitter):\n",
    "    \"\"\"Read image files and return a list of chunks of documents with captions.\"\"\"\n",
    "    return load_and_split_document(ImageCaptionLoader, image_path, splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myne-project-plan'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf'\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "    chunk_overlap=200, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "# splits = splitter.split_documents(pages1)\n",
    "\n",
    "# docs = read_pdf(pdf_path=pdf_path,\n",
    "#          splitter=splitter)\n",
    "\n",
    "os.path.basename(pdf_path).split('.')[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='M y n e\\nW e b - A p p l i c a t i o n \\n( C u s t o m A I\\nD r i v e n \\nM o d e l )\\nM a y\\n1 4 ,\\n2 0 2 4\\nO v e r v i e w\\nM y n e\\nW e b\\nA p p l i c a t i o n\\ni s\\na\\np l a t f o r m\\nf r o m\\nw h i c h\\nd i f f e r e n t\\nt y p e s\\no f\\nu s e r s\\nc a n\\nl o g i n\\na n d\\nu p l o a d\\nd o c u m e n t s\\nu s i n g\\nO p e n\\nA I ,\\na n d\\nt h e\\ns y s t e m\\nw i l l\\nr e s p o n d\\nt o\\nc l i e n t\\nq u e r i e s\\nb a s e d\\no n\\nu p l o a d e d\\nd o c u m e n t s .\\nS o m e\\np r e d e ﬁ n e d\\nt e m p l a t e\\nm o d e l s\\nw i l l\\nb e\\nt h e r e\\nt o\\nr e p r e s e n t\\nt h e\\nq u e r y\\nr e s p o n s e s .\\nT h e r e\\nw i l l\\nb e\\nf o l l o w i n g\\nu s e r\\nr o l e s\\nf o r\\nt h e\\nw e b - p o r t a l :\\n-\\nSuper\\nAdmin\\n-controls\\nthe\\nentire\\nsystem\\nand\\nhas\\nthe\\nability\\nto\\nturn\\non/off,\\nlimit\\naccess.\\nThese\\nfunctions\\nshould\\nbe\\nlinked\\nto\\nthe\\nCXM.\\n*Need\\nto\\nfigure\\nhow\\nto\\nlink\\nthis\\naccess\\nto\\nthe\\nnew\\nCXM*\\n-\\nClient\\nAdmin\\n-\\ncan\\nview\\nthe\\ntotal\\nusage,\\ncosts,\\nbilling,\\nuser\\nlist,\\nand\\nsearches,\\ncan\\nenable\\nand\\ndisable\\nusers.\\n-\\nSr.\\nStaff\\nUser\\n-\\ncan\\nsee', metadata={'source': 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf', 'page': 0}),\n",
       " Document(page_content='*Need\\nto\\nfigure\\nhow\\nto\\nlink\\nthis\\naccess\\nto\\nthe\\nnew\\nCXM*\\n-\\nClient\\nAdmin\\n-\\ncan\\nview\\nthe\\ntotal\\nusage,\\ncosts,\\nbilling,\\nuser\\nlist,\\nand\\nsearches,\\ncan\\nenable\\nand\\ndisable\\nusers.\\n-\\nSr.\\nStaff\\nUser\\n-\\ncan\\nsee\\nall\\ndata\\nbut\\nnot\\nthe\\nsame\\nlevel\\nas\\nthe\\nclient\\nadmin.\\n-\\nStaff\\nUser\\n-\\ncan\\nmake\\nsearches\\nwithin\\nthe\\nparameters\\nthat\\nhave\\nbeen\\nallowed\\nby\\nthe\\nSr.\\nStaff\\nUser\\nand/or\\nClient\\nAdmin.\\nEach\\nuser\\nwill\\nhave\\na\\nmodified\\ndashboard\\nthat\\nshows\\nall\\nof\\nthis\\ncontent.\\nUsers\\ncan\\nclick\\non\\na\\nlink\\nto\\npreviously\\nsearched\\ncontent\\nto\\nbring\\nit\\nup\\nagain\\n(There\\nis\\nlikely\\na\\nretrieval\\ncost\\nfor\\nthis\\nso\\nwe\\nneed\\nto\\nfactor\\nit\\ninto\\nthe\\npricing\\nmodel).\\nA r c h i t e c t u r e\\n1', metadata={'source': 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf', 'page': 0}),\n",
       " Document(page_content='We\\nhave\\ndivided\\nthe\\nproject\\ninto\\n2\\nparts.\\nD a t a b a s e\\nD r i v e n\\n-\\nM i l e s t o n e s\\n1 )\\nRequir ement\\nAnalysis\\nN e e d\\nt o\\np l a n\\na n d\\nu n d e r s t a n d\\nt h e\\np r o j e c t\\nr e q u i r e m e n t s ,\\ng a t h e r i n g\\na l l\\nt h e\\nk n o w l e d g e\\na n d\\nO p e n A I\\nc o n c e p t s\\nt o\\nu n d e r s t a n d\\na n d\\nb u i l d\\nt h e\\nw e b s i t e .\\n2)\\nDesign\\nF r o n t - e n d\\nd e s i g n e r\\nr e q u i r e d\\nf o r\\nm a k i n g\\nc u s t o m\\nt e m p l a t e s .\\n2\\nMYNE AI Delivery Model\\nMobile Aocess\\nUpload File\\nExport Content to\\nFile Outputto\\nFile\\nCoded Template\\nOn The Go\\nWG Access Control\\nSearch/Refine\\nndino\\nTrained AI\\nTemplate/Long\\nStyle of\\nLink to server\\nQuery Response\\nafedqoW\\nVs. Short Book\\nEdiable Content\\nDatabase Driven\\nChent Query\\nAuto Generated Container/Selected Template\\nTemplate section Heading\\nTemplate Body Copy\\n.pdf,.docx, .txt', metadata={'source': 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf', 'page': 1}),\n",
       " Document(page_content='3 )\\nDe v elopment\\na)\\nW or dpr ess\\nPr oject\\nSet-up\\nR e q u i r e m e n t :\\ns e r v e r\\ns p a c e\\na n d\\nd a t a b a s e\\ns e t u p\\nn e e d\\nt o\\nb e\\nc o m p l e t e d .\\nb)\\nWP\\nTheme\\nSelection\\nW P\\nP r o j e c t\\nt h e m e\\nn e e d\\nt o\\nb e\\ns e l e c t e d ,\\nu p l o a d e d\\na n d\\na c t i v a t e d .\\nc)\\nW eb-pages\\nand\\nPlugin\\nDe v elopment\\nF r o n t - e n d\\np a g e s\\nt o\\nb e\\nc r e a t e d\\nt o\\nu p l o a d\\nd o c u m e n t s\\na n d\\ns h o w\\nr e s p o n s e s .\\nd)\\nOpenAI\\nconnectivity\\n( * w e\\nm a y\\nr e q u i r e\\nA I - M L\\nd e v e l o p e r\\na t\\nt h i s\\ns t a g e )\\ni )\\nC o n n e c t\\nt o\\nO p e n A I\\nA P I\\nt o\\nu p l o a d\\nﬁ l e s\\n( p d f / d o c )\\nR e s p o n s e\\n:\\nF i l e / M e d i a\\nI D\\n( r e s p e c t i v e\\nr e s p o n s e s\\nf r o m\\nA P I )\\ni i )\\nC o n n e c t\\nt o\\nO p e n A I\\nt o\\np r o c e s s\\nc l i e n t\\nq u e r y\\ni n\\nt h e\\nu p l o a d e d\\nd o c u m e n t\\nR e s p o n s e\\n:\\nq u e r y\\nr e s u l t s\\nf r o m\\nd o c u m e n t\\ne)\\nT emplates\\nIntegr ation\\nN e e d\\nf r o n t - e n d\\nd e s i g n e r\\nt o\\nb u i l d', metadata={'source': 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf', 'page': 2}),\n",
       " Document(page_content='i n\\nt h e\\nu p l o a d e d\\nd o c u m e n t\\nR e s p o n s e\\n:\\nq u e r y\\nr e s u l t s\\nf r o m\\nd o c u m e n t\\ne)\\nT emplates\\nIntegr ation\\nN e e d\\nf r o n t - e n d\\nd e s i g n e r\\nt o\\nb u i l d\\nc u s t o m\\nt e m p l a t e s\\nt o\\ns h o w\\nq u e r y\\nr e s u l t s\\ni n\\nr e q u i r e d\\nf o r m a t .\\nf )\\nPricing\\nModel\\nT h i s\\nn e e d s\\nt o\\nb e\\np l a n n e d\\na n d\\nﬁ n a l i z e d .\\n4)\\nT esting\\n5)\\nDeplo yment\\n6)\\nMaintenance\\n3', metadata={'source': 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf', 'page': 2}),\n",
       " Document(page_content='O n\\nt h e\\nG O\\n-\\nM i l e s t o n e s\\n4', metadata={'source': 'artifacts/06_26_2024_12_48_34/file_storage/testmyne45/myne-project-plan.pdf', 'page': 3})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Test Results\\n\\nData\\n\\nRevenues\\n\\nThe following table sets forth our combined statements of income data (in thousands):\\n\\nWe had revenue of \\x0b$ 116,609 in 2011\\n\\nWe had revenue of \\n\\n$ 117,029 in 2025\\n\\nWe had revenue of $85,965 in 2020', metadata={'source': 'research/test_docs/Test Case112923  Compared to Meta CSV File.ppt'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Install packages\n",
    "# %pip install unstructured\n",
    "# %pip install python-magic\n",
    "# %pip install python-pptx\n",
    "read_ppt(\"research/test_docs/Test Case112923  Compared to Meta CSV File.ppt\",\n",
    "         splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Upload a File\\n\\nHey how are you doing? We are testing the html file loading. By the way,let's talk about langchain.\\n\\n        LangChain is a framework designed for developing applications powered by language models. It provides a suite of tools and abstractions to facilitate the creation and integration of language models into various applications, especially those involving complex workflows and tasks. LangChain helps streamline the process of connecting language models with data sources, APIs, and other components necessary for building sophisticated language-driven applications.\\n\\nKey features of LangChain include:\\n\\nIntegration with Various Language Models: LangChain supports integration with multiple language models, making it easier to switch between models or use multiple models within a single application.\", metadata={'source': 'research/test_docs/test.html'}),\n",
       " Document(page_content='Integration with Various Language Models: LangChain supports integration with multiple language models, making it easier to switch between models or use multiple models within a single application.\\n\\nData Connectivity: LangChain provides connectors to various data sources, allowing language models to interact with and retrieve data from databases, APIs, and other external sources.\\n\\nCustom Workflows: The framework allows developers to define custom workflows that leverage the capabilities of language models. This includes chaining together multiple operations, handling different types of inputs and outputs, and managing the flow of data within the application.\\n\\nUtility Functions: LangChain includes a set of utility functions and tools to simplify common tasks in language model development, such as text processing, data formatting, and API interaction.', metadata={'source': 'research/test_docs/test.html'}),\n",
       " Document(page_content='Utility Functions: LangChain includes a set of utility functions and tools to simplify common tasks in language model development, such as text processing, data formatting, and API interaction.\\n\\nExtensibility: The framework is designed to be extensible, allowing developers to add new functionalities, integrate additional tools, and customize the behavior of the language models as needed.\\n\\nDeployment and Scalability: LangChain supports deployment in various environments, from local development to cloud-based production systems. It also includes features for scaling applications to handle large volumes of requests and data.\\n\\nOverall, LangChain aims to make it easier for developers to build, deploy, and manage applications that leverage the power of language models, enabling more efficient and effective use of these technologies in real-world scenarios.', metadata={'source': 'research/test_docs/test.html'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_html(\"research/test_docs/test.html\", splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='CONTRACTOR’S RESPONSIBILITY FOR PROJECT SAFETY\\nGuidance\\nContract \\n1. Contractor recognizes the importance of performing the Work in a safe and responsible manner so as to prevent damage, injury, or loss to individuals, the environment, and the Work, including materials and equipment incorporated into the Work or stored on-site or off-site. Contractor assumes responsibility for implementing and monitoring all Environment, Health & Safety (EHS) precautions and programs related to the performance of the Work.\\n2. Contractor and Subcontractors shall comply with all legal and Owner-specific reporting', metadata={'source': 'research/test_docs/Contractor Guidelines_ort.txt'}),\n",
       " Document(page_content='2. Contractor and Subcontractors shall comply with all legal and Owner-specific reporting\\nrequirements relating to EHS set forth in the Contract Documents. Contractor will immediately report oral, and in writing within two (2) days, any EHS related injury, loss, damage, or accident arising from the Work to Owner’s Representative and, to the extent mandated by legal requirements, to all government or quasi-government authorities having jurisdiction over safety-related matters involving the Project or the Work. Contractor and its Subcontractors will immediately report to the Owner’s Representative all non-incidental spills, and all other significant impacts to the environment (soil, water, air) in performance of the Work. Contractor will also immediately notify the Owner of any failure to comply with state and federal environmental laws, rules, and regulations.', metadata={'source': 'research/test_docs/Contractor Guidelines_ort.txt'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_txt(\"research/test_docs/Contractor Guidelines_ort.txt\", splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = read_docx(\"research/test_docs/112423 Google Drive Folder Test Outline v1 (1).docx\", splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Tron Electrical & Automation: Google Review Campaign\\n\\nThe purpose of the Google Review Campaign was to gain immediate feedback from customers about the technicians’ service. The intrinsic benefit to the campaign is growing Tron’s email marketing list.\\n\\nCampaign Duration: May 7th, 2023 to May 31st, 2023. \\n\\nThe performance metrics available are listed below:\\n\\nNew Subscribers\\n\\n\\n\\nSubscriber1@email.com\\n\\nSubscriber2@email.com\\n\\nSubscriber3@email.com\\n\\nSubscriber4@email.com\\n\\n\\n\\nThe number of submissions during the Period is 17.\\n\\nThe technician that used the Google Review campaign on the DCard was John Ricupero with 82.4% of responses.\\n\\nAll of these email addresses alongside the name of the technician that submitted the information is stored in the Tron email marketing account.', metadata={'source': 'research/test_docs/112423 Google Drive Folder Test Outline v1 (1).docx'}),\n",
       " Document(page_content='All of these email addresses alongside the name of the technician that submitted the information is stored in the Tron email marketing account.\\n\\nRecommendations.\\nIncentive Program. To encourage the other technicians to participate in the campaigns. Restructuring the current incentive package could help. Without direct encouragement, the Organization is unable to confirm whether the technician is properly introducing themselves before and after the service is provided. Strong customer service is the backbone of Tron’s success. As such, reinforcing this core value throughout its client engagements is essential.\\n\\nPaid Account. Transitioning to a paid email account will increase the scope of the automations that can be leveraged on Tron’s behalf. Further, deeper metrics and learning is available to the marketing team.\\n\\n\\nCampaign Structure\\nSource: DCard\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nContact Stored in Marketing \\nDatabase for Retargeting\\n\\nContact Stored in Marketing \\nDatabase for Retargeting', metadata={'source': 'research/test_docs/112423 Google Drive Folder Test Outline v1 (1).docx'}),\n",
       " Document(page_content='Campaign Structure\\nSource: DCard\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nContact Stored in Marketing \\nDatabase for Retargeting\\n\\nContact Stored in Marketing \\nDatabase for Retargeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTron Electrical & Automation_May Primer Google Review Campaign Report Page 2 of 2', metadata={'source': 'research/test_docs/112423 Google Drive Folder Test Outline v1 (1).docx'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of these email addresses alongside the name of the technician that submitted the information is stored in the Tron email marketing account.\n",
      "\n",
      "Recommendations.\n",
      "Incentive Program. To encourage the other technicians to participate in the campaigns. Restructuring the current incentive package could help. Without direct encouragement, the Organization is unable to confirm whether the technician is properly introducing themselves before and after the service is provided. Strong customer service is the backbone of Tron’s success. As such, reinforcing this core value throughout its client engagements is essential.\n",
      "\n",
      "Paid Account. Transitioning to a paid email account will increase the scope of the automations that can be leveraged on Tron’s behalf. Further, deeper metrics and learning is available to the marketing team.\n",
      "\n",
      "\n",
      "Campaign Structure\n",
      "Source: DCard\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Contact Stored in Marketing \n",
      "Database for Retargeting\n",
      "\n",
      "Contact Stored in Marketing \n",
      "Database for Retargeting\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import S3DirectoryLoader\n",
    "\n",
    "loader = S3DirectoryLoader(\"testmyne45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The MIME type of '/tmp/tmpwmdxv3nx/myne-user-onboarding.mp4' is 'video/webm'. This file type is not currently supported in unstructured.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid file /tmp/tmpwmdxv3nx/myne-user-onboarding.mp4. The FileType.UNK file type is not supported in partition.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/official/myne/myne-ml-serve/env/lib/python3.10/site-packages/langchain_community/document_loaders/s3_directory.py:139\u001b[0m, in \u001b[0;36mS3DirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     loader \u001b[38;5;241m=\u001b[39m S3FileLoader(\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbucket,\n\u001b[1;32m    128\u001b[0m         obj\u001b[38;5;241m.\u001b[39mkey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m         boto_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_config,\n\u001b[1;32m    138\u001b[0m     )\n\u001b[0;32m--> 139\u001b[0m     docs\u001b[38;5;241m.\u001b[39mextend(\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m~/official/myne/myne-ml-serve/env/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/official/myne/myne-ml-serve/env/lib/python3.10/site-packages/langchain_community/document_loaders/unstructured.py:88\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/official/myne/myne-ml-serve/env/lib/python3.10/site-packages/langchain_community/document_loaders/s3_file.py:135\u001b[0m, in \u001b[0;36mS3FileLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(file_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    134\u001b[0m s3\u001b[38;5;241m.\u001b[39mdownload_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbucket, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey, file_path)\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstructured_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/official/myne/myne-ml-serve/env/lib/python3.10/site-packages/unstructured/partition/auto.py:548\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, content_type, file, file_filename, url, include_page_breaks, strategy, encoding, paragraph_grouper, headers, skip_infer_table_types, ssl_verify, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, xml_keep_tags, data_source_metadata, metadata_filename, request_timeout, hi_res_model_name, model_name, date_from_file_object, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. The \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiletype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file type is not supported in partition.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements:\n\u001b[1;32m    551\u001b[0m     element\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m url\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file /tmp/tmpwmdxv3nx/myne-user-onboarding.mp4. The FileType.UNK file type is not supported in partition."
     ]
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting amazon-textract-textractor\n",
      "  Downloading amazon_textract_textractor-1.8.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.10/site-packages (from amazon-textract-textractor) (10.3.0)\n",
      "Requirement already satisfied: XlsxWriter<4,>=3.0 in ./env/lib/python3.10/site-packages (from amazon-textract-textractor) (3.2.0)\n",
      "Requirement already satisfied: amazon-textract-caller<1,>=0.2.4 in ./env/lib/python3.10/site-packages (from amazon-textract-textractor) (0.2.4)\n",
      "Collecting editdistance<0.9,>=0.6.2 (from amazon-textract-textractor)\n",
      "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tabulate<0.10,>=0.9 in ./env/lib/python3.10/site-packages (from amazon-textract-textractor) (0.9.0)\n",
      "Requirement already satisfied: boto3>=1.26.35 in ./env/lib/python3.10/site-packages (from amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.34.131)\n",
      "Requirement already satisfied: botocore in ./env/lib/python3.10/site-packages (from amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.34.131)\n",
      "Requirement already satisfied: amazon-textract-response-parser>=0.1.39 in ./env/lib/python3.10/site-packages (from amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.0.3)\n",
      "Requirement already satisfied: marshmallow<4,>=3.14 in ./env/lib/python3.10/site-packages (from amazon-textract-response-parser>=0.1.39->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (3.21.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./env/lib/python3.10/site-packages (from boto3>=1.26.35->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in ./env/lib/python3.10/site-packages (from boto3>=1.26.35->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./env/lib/python3.10/site-packages (from botocore->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./env/lib/python3.10/site-packages (from botocore->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (2.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./env/lib/python3.10/site-packages (from marshmallow<4,>=3.14->amazon-textract-response-parser>=0.1.39->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.16.0)\n",
      "Downloading amazon_textract_textractor-1.8.2-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.6/307.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: editdistance, amazon-textract-textractor\n",
      "Successfully installed amazon-textract-textractor-1.8.2 editdistance-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install amazon-textract-textractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
    "\n",
    "from docx2pdf import convert\n",
    "\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"s3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "pdf_path = 'research/test_docs/112423 Google Drive Folder Test Outline v1.pdf'\n",
    "\n",
    "loader = PyPDFLoader(pdf_path, extract_images=True)\n",
    "pages1 = loader.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"WG\\n\\n\\nTron Electrical & Automation: Google Review Campaign\\n\\n\\nThe purpose of the Google Review Campaign was to gain immediate feedback from\\n\\n\\ncustomers about the technicians' service. The intrinsic benefit to the campaign is\\n\\n\\ngrowing Tron's email marketing list.\\n\\n\\nCampaign Duration: May 7th, 2023 to May 31st, 2023.\\n\\n\\nThe performance metrics available are listed below:\\n\\n\\nNew Subscribers\\n\\n\\nSubscriber1@email.com\\n\\n\\nSubscriber2@email.com\\n\\n\\nSubscriber3@email.com\\n\\n\\nSubscriber4@email.com\\n\\n\\nThe number of submissions during the Period is 17.\\n\\n\\nThe technician that used the Google Review campaign on the DCard was John\\n\\n\\nRicupero with 82.4% of responses.\\n\\n\\nAll of these email addresses alongside the name of the technician that submitted\\n\\n\\nthe information is stored in the Tron email marketing account.\\n\\n\\nRecommendations.\\n\\n\\nIncentive Program. To encourage the other technicians to participate in the\\n\\n\\ncampaigns. Restructuring the current incentive package could help. Without direct\", metadata={'source': 's3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf', 'page': 1}),\n",
       " Document(page_content=\"Recommendations.\\n\\n\\nIncentive Program. To encourage the other technicians to participate in the\\n\\n\\ncampaigns. Restructuring the current incentive package could help. Without direct\\n\\n\\nencouragement, the Organization is unable to confirm whether the technician is\\n\\n\\nproperly introducing themselves before and after the service is provided. Strong\\n\\n\\ncustomer service is the backbone of Tron's success. As such, reinforcing this core\\n\\n\\nvalue throughout its client engagements is essential.\\n\\n\\nPaid Account. Transitioning to a paid email account will increase the scope of the\\n\\n\\nautomations that can be leveraged on Tron's behalf. Further, deeper metrics and\\n\\n\\nlearning is available to the marketing team.\\n\\n\\nCampaign Structure\\n\\n\\nSource: DCard\\n\\n\\nTron Electrical & Automation_May Primer Google Review Campaign Report Page 1 of 3\", metadata={'source': 's3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf', 'page': 1}),\n",
       " Document(page_content=\"TRON\\n\\n\\nAUT OMA TION\\n\\n\\nX\\n\\n\\nYour Experience Matters to Us\\n\\n\\nName*\\n\\n\\nEmail*\\n\\n\\nPhone\\n\\n\\nSubmit\\n\\n\\nJoseph Cerasuolo\\n\\n\\nOperations & Team Leader\\n\\n\\nTron Electrical & Automation\\n\\n\\nCertified Master Electrician #6015080\\n\\n\\nTron Electrical & Automation\\n\\n\\ni Write a review\\n\\n\\n71 Silton Rd # Woodbridge ON\\n\\n\\nMobile\\n\\n\\nWebsite\\n\\n\\nEmail\\n\\n\\n4.9 *****\\n\\n\\n190 reviews 1\\n\\n\\nPeople often mention\\n\\n\\njob\\n\\n\\nwork\\n\\n\\nlights\\n\\n\\n10\\n\\n\\n+6\\n\\n\\nSave contact\\n\\n\\nSort by\\n\\n\\nMos relevant\\n\\n\\nNewest\\n\\n\\nHighest\\n\\n\\nLowest\\n\\n\\nMarilyn Sclater\\n\\n\\nM\\n\\n\\n2 reviews\\n\\n\\n***** 2 days ago NEW\\n\\n\\nPositive: Professionalism Punctuality Quality Responsiveness\\n\\n\\nGoogle\\n\\n\\nThe electrician Ali, was professional on time pleasant and did the job expertly Couldn't ask for more\\n\\n\\nCustomer Reviews\\n\\n\\n*****\\n\\n\\nCertifications\\n\\n\\nAgency\\n\\n\\nLicence Number\\n\\n\\nof the\\n\\n\\nElectrical\\n\\n\\nSafety\\n\\n\\n6015080\\n\\n\\nAuthority\\n\\n\\nOCOT 13224623\\n\\n\\nGIUSEPPE L CERASUOLO\\n\\n\\n2021-09-15\\n\\n\\n2026-09-14\\n\\n\\nEffective Date\\n\\n\\nExpiry Date\\n\\n\\nMASTER ELECTRICIAN LICENCE\", metadata={'source': 's3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf', 'page': 2}),\n",
       " Document(page_content='Licence Number\\n\\n\\nof the\\n\\n\\nElectrical\\n\\n\\nSafety\\n\\n\\n6015080\\n\\n\\nAuthority\\n\\n\\nOCOT 13224623\\n\\n\\nGIUSEPPE L CERASUOLO\\n\\n\\n2021-09-15\\n\\n\\n2026-09-14\\n\\n\\nEffective Date\\n\\n\\nExpiry Date\\n\\n\\nMASTER ELECTRICIAN LICENCE\\n\\n\\nTron Electrical & Automation_May Primer Google Review Campaign Report Page 2 of 3', metadata={'source': 's3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf', 'page': 2}),\n",
       " Document(page_content='P1\\n\\n\\nP2\\n\\n\\nP3\\n\\n\\nP4\\n\\n\\nP5\\n\\n\\nTron Electrical & Automation May Primer Google Review Campaign Report Page 3 of 3', metadata={'source': 's3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf', 'page': 3})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path_s3 = \"s3://testmyne45/112423 Google Drive Folder Test Outline v1.pdf\"\n",
    "read_pdf_aws(pdf_path_s3, splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Contact\\n\\n\\nHrisikesh Neogi\\n\\n\\nhriskeshneogi@gmail.com\\n\\n\\nSoftware Engineer@CN I Gen All I NLP I LLM I LangChain I Prompt\\n\\n\\nwwwJinkedin.com/in/hrisikesh-\\n\\n\\nEngineering I Machine Learning I YouTuber @HrisikeshUnleashesAl\\n\\n\\nneogi (Linked In)\\n\\n\\nBengaluru Karnataka India\\n\\n\\nwww.facebook.cam/dishi0163\\n\\n\\n(Personal)\\n\\n\\nSummary\\n\\n\\nTop Skills\\n\\n\\nA combination of Arts and Science. a data enthusiast with a passion\\n\\n\\nGt\\n\\n\\nfor data-driven problem-solving. Prior a B.A. student, now A Data\\n\\n\\nvector db\\n\\n\\nGeek Where B.A gives pleasure. Data Science gives a joy of\\n\\n\\nlangchain\\n\\n\\ncreativity, the power of A.I. and both the Arts and Science, create a\\n\\n\\nhuge pillar for building any solutions\\n\\n\\nA Bengali by heart An Indian by culture.\\n\\n\\nExperience\\n\\n\\nCapital Numbers\\n\\n\\nSoftware Engineer ( Gen Al/AIML)\\n\\n\\nMay 2024 - Present (2 months)\\n\\n\\nKolkata West Bengal India\\n\\n\\nPW (PhysicsWallah)\\n\\n\\nAssociate Manager and Data Scientist\\n\\n\\nOctober 2023 - May 2024 (8 months)\\n\\n\\nBangalore Urban Karnataka India\\n\\n\\niNeuron.ai', metadata={'source': 'research/test_docs/Screenshot_test.png', 'page': 1}),\n",
       " Document(page_content='Kolkata West Bengal India\\n\\n\\nPW (PhysicsWallah)\\n\\n\\nAssociate Manager and Data Scientist\\n\\n\\nOctober 2023 - May 2024 (8 months)\\n\\n\\nBangalore Urban Karnataka India\\n\\n\\niNeuron.ai\\n\\n\\n2 years 4 months\\n\\n\\nJr. Data Scientist\\n\\n\\nJanuary 2022 - October 2023 (1 year 10 months)\\n\\n\\nBengaluru Karnataka India\\n\\n\\nAjourney of light A journey of hope Ajourney of positivity\\n\\n\\nData Science Intern\\n\\n\\nJuly 2021', metadata={'source': 'research/test_docs/Screenshot_test.png', 'page': 1})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_pdf_aws(images_path, splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
